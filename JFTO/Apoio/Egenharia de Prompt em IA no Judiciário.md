# Engenharia de Prompt em IA no Judiciário: Diretrizes Conceituais e Metodológicas de Boas Práticas

## Introdução

O uso de **inteligência artificial (IA)** no Poder Judiciário brasileiro vem se intensificando, impulsionando a criação de normas específicas para garantir sua aplicação ética e eficaz. Em março de 2025, o Conselho Nacional de Justiça (CNJ) editou a Resolução n.º 615/2025, atualizando diretrizes da Res. 332/2020, a fim de **estabelecer parâmetros de desenvolvimento, utilização e governança de soluções de IA no Judiciário** ([](https://www.tjsp.jus.br/Download/SecaoDireitoPublico/Pdf/Cadip/INF-ESPECIAL-CADIP-IA-2ed-2025-03-26.pdf#:~:text=%C3%A9tica%2C%20transpar%C3%AAncia%20e%20governan%C3%A7a%20na,rigorosas%20para%20a%20prote%C3%A7%C3%A3o%20de)). Dentre essas diretrizes, destacam-se princípios fundamentais como ética, transparência, não discriminação, proteção de dados e responsabilidade na adoção de modelos de IA ([](https://www.tjsp.jus.br/Download/SecaoDireitoPublico/Pdf/Cadip/INF-ESPECIAL-CADIP-IA-2ed-2025-03-26.pdf#:~:text=%C3%A9tica%2C%20transpar%C3%AAncia%20e%20governan%C3%A7a%20na,rigorosas%20para%20a%20prote%C3%A7%C3%A3o%20de)) ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=Art,auxiliem%20no%20julgamento%20justo%20e)). Nesse contexto, a **engenharia de prompt** – isto é, a elaboração cuidadosa dos comandos ou perguntas em linguagem natural fornecidos a sistemas de IA generativa ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=XV%20%E2%80%93%20privacy%20by%20default%3A,execu%C3%A7%C3%A3o%20de%20uma%20tarefa%20espec%C3%ADfica)) – emerge como prática essencial para orientar o comportamento dessas ferramentas de forma alinhada aos valores jurídicos e requisitos normativos.

A **engenharia de prompt** adequada permite otimizar a interação com modelos de linguagem, melhorando a qualidade, precisão e relevância das respostas geradas ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=A%20efic%C3%A1cia%20da%20IA%20depende,jur%C3%ADdicas%20e%20aumentar%20sua%20efici%C3%AAncia)). No âmbito judicial, prompts bem construídos podem **aumentar a consistência das argumentações jurídicas e a eficiência no tratamento de casos**, ao passo que prompts mal formulados podem gerar respostas imprecisas, enviesadas ou incompatíveis com a ética e a lei ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=A%20efic%C3%A1cia%20da%20IA%20depende,jur%C3%ADdicas%20e%20aumentar%20sua%20efici%C3%AAncia)). Este relatório apresenta diretrizes conceituais e metodológicas de boas práticas em engenharia de prompt para IA no Judiciário brasileiro, com base nas normas do CNJ (especialmente a Res. CNJ 615/2025) e em insights de literatura acadêmica e de portais especializados, nacionais e internacionais. Serão enfatizados os seguintes aspectos: (1) princípios éticos e transparência na construção de prompts; (2) proteção de dados (conformidade com a LGPD); (3) redução de vieses e promoção de imparcialidade; (4) garantia de acurácia, rastreabilidade e auditabilidade das respostas; (5) técnicas robustas para prompts confiáveis, seguros e eficientes em contexto jurídico; e (6) frameworks e recomendações adotados em instituições públicas similares. Sempre que possível, incluem-se **exemplos práticos** e citações de fontes relevantes para ilustrar cada ponto.

## Princípios Éticos e Transparência na Construção de Prompts

A adoção de IA no Judiciário deve observar os **princípios éticos fundamentais e de transparência**, de modo a **preservar a integridade da função jurisdicional** ([AI Judicial Guidance](https://www.judiciary.uk/wp-content/uploads/2023/12/AI-Judicial-Guidance.pdf#:~:text=them,Common%20Terms)). Conforme a Resolução CNJ 615/2025, o uso responsável de IA tem como princípios a *justiça, equidade, inclusão e não discriminação abusiva*, bem como a *transparência, explicabilidade, auditabilidade e confiabilidade* das soluções de IA ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=Art,discrimina%C3%A7%C3%A3o%20abusiva%20ou%20il%C3%ADcita)). Isso significa que, desde a concepção dos prompts, é preciso **zelar para que a IA não viole direitos fundamentais ou gere opacidade nos processos decisórios**. A resolução reforça que a utilização de IA deve estar *“em consonância com valores éticos fundamentais, incluindo dignidade humana, respeito aos direitos humanos, não discriminação, devido processo [...] prestação de contas e responsabilização”* ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=Judici%C3%A1rio%2C%20com%20plena%20transpar%C3%AAncia%20e,presta%C3%A7%C3%A3o%20de%20contas%20e%20responsabiliza%C3%A7%C3%A3o)). Assim, um prompt jamais deve induzir a IA a produzir conteúdo que fira a dignidade das partes, que contenha preconceitos ou que comprometa o devido processo legal.

**Transparência** implica que os usuários (juízes, servidores ou jurisdicionados) saibam quando estão interagindo com um sistema de IA e compreendam suas limitações. Boas práticas incluem informar claramente, sempre que cabível, que o texto ou sugestão foi gerado por IA. A Res. 615/2025 determina, por exemplo, que usuários externos sejam **avisados de forma clara e acessível sobre o uso de sistemas de IA** em serviços judiciais prestados ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=Art,linguagem%20simples%2C%20que%20possibilite%20a)). De forma semelhante, diretrizes internacionais recomendam **comunicação aberta sobre o emprego de IA em tarefas de alto impacto**, incluindo divulgação de assistência por IA às partes relevantes e registro transparente dos usos da IA nos processos ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=Courts%20must%20maintain%20open%20and,facing%20GenAI)) ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=application%20must%20include%20a%20clear,Fairness%20and%20Bias%20Prevention)). Um prompt bem elaborado pode contribuir com a transparência ao solicitar que o modelo **explique seu raciocínio ou indique as fontes de informação** utilizadas na resposta. Essa abordagem torna a saída da IA mais compreensível e verificável pelo usuário humano, aumentando a confiança no sistema. Conforme destaca Mora (2025), *“uma engenharia de prompt responsável inclui incorporar restrições éticas diretamente nos prompts”*, canalizando a IA para resultados benéficos e minimizando danos potenciais ([The Art and Science of Prompt Engineering: Unlocking AI’s True Potential in 2025 | by SHREEDEVI T S | Apr, 2025 | Medium](https://medium.com/@Shreedevi-TS/the-art-and-science-of-prompt-engineering-unlocking-ais-true-potential-in-2025-346154144ac1#:~:text=%E2%80%9CResponsible%20prompt%20engineering%20includes%20designing,%E2%80%9D)). Em outras palavras, o projetista de prompts deve considerar não apenas **o que a IA pode fazer, mas o que **deve** fazer** ([The Art and Science of Prompt Engineering: Unlocking AI’s True Potential in 2025 | by SHREEDEVI T S | Apr, 2025 | Medium](https://medium.com/@Shreedevi-TS/the-art-and-science-of-prompt-engineering-unlocking-ais-true-potential-in-2025-346154144ac1#:~:text=As%20prompt%20engineering%20has%20grown,but%20what%20it%20should%20do)), orientando o modelo a respeitar limites éticos (por exemplo, instruindo-o a **não fornecer aconselhamento jurídico definitivo em consultas que exigem decisão humana** ou a **não emitir opiniões tendenciosas**).

Para garantir transparência e responsabilidade, também é vital **registrar e auditar as interações** com a IA. Prompts e respostas devem ser logados em sistemas seguros, permitindo posterior revisão. A **contestabilidade** – isto é, a possibilidade de questionar e revisar resultados gerados pela IA – é apontada como princípio pelo CNJ ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=sempre%20que%20tecnicamente%20poss%C3%ADvel%3B%20XVIII,CAP%C3%8DTULO%20II)). Isso exige que, se uma resposta de IA influenciar uma decisão judicial, haja **mecanismos para revisar criticamente essa resposta**, com intervenção humana. De fato, a Res. 615/2025 impõe **supervisão humana efetiva** em todas as fases do ciclo de vida da IA, assegurando que o magistrado **tenha sempre a palavra final** e possa modificar qualquer resultado produzido pela máquina ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=Art,pela%20intelig%C3%AAncia%20artificial%2C%20sempre%20que)). Assim, do ponto de vista da engenharia de prompt, deve-se **construir as instruções prevendo a validação humana** – por exemplo, incluindo lembretes no output para o usuário verificar informações ou limites na atuação da IA (*“Nota: Esta resposta é gerada por IA e deve ser conferida pelo responsável antes de uso”*). Tais práticas reforçam a prestação de contas (accountability) e a **transparência do processo**, em consonância com as diretrizes éticas nacionais e internacionais ([Prompt injections e accountability em sistemas de IA - Migalhas](https://www.migalhas.com.br/coluna/migalhas-de-protecao-de-dados/428264/prompt-injections-e-accountability-em-sistemas-de-ia#:~:text=A%20gravidade%20dos%20prompt%20injections,a%20conten%C3%A7%C3%A3o%20de%20eventuais%20manipula%C3%A7%C3%B5es)) ([Prompt injections e accountability em sistemas de IA - Migalhas](https://www.migalhas.com.br/coluna/migalhas-de-protecao-de-dados/428264/prompt-injections-e-accountability-em-sistemas-de-ia#:~:text=Pol%C3%ADticas%20corporativas%20robustas%20de%20seguran%C3%A7a,e%20antecipar%20a%20vulnerabilidades%20ocultas)).

## Proteção de Dados Pessoais e LGPD nos Prompts

No âmbito do Judiciário, onde lida-se com informações sensíveis de pessoas físicas, a **proteção de dados pessoais** é um imperativo na utilização de IA. A Lei Geral de Proteção de Dados (LGPD, Lei n.º 13.709/2018) estabelece bases legais e princípios para o tratamento de dados pessoais, os quais devem ser rigorosamente observados em sistemas de IA, inclusive no **projeto de prompts**. A Resolução CNJ 615/2025 enfatiza a **proteção de dados e privacidade** como um de seus pilares ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=VIII%20%E2%80%93%20a%20prote%C3%A7%C3%A3o%20de,permitida%20a%20contrata%C3%A7%C3%A3o%20de%20fontes)), prevendo **privacy by design** (privacidade desde a concepção do sistema) e **privacy by default** (configurações padrão que resguardem a confidencialidade) ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=XIV%20%E2%80%93%20privacy%20by%20design%3A,execu%C3%A7%C3%A3o%20de%20uma%20tarefa%20espec%C3%ADfica)). Isso significa que, ao elaborar prompts ou configurações de um modelo de linguagem para uso judicial, deve-se **evitar expor informações pessoais desnecessárias** e adotar medidas de anonimização sempre que possível.

Uma das boas práticas fundamentais é **não inserir em prompts dados que permitam identificar indivíduos**, a menos que absolutamente necessário para a finalidade legítima. Mesmo quando for preciso fornecer detalhes de um caso real à IA (por exemplo, para obter um resumo ou parecer), recomenda-se **pseudonimizar ou generalizar informações pessoais** (como usar iniciais no lugar de nomes reais, ou substituir números de processo por identificadores genéricos). A Res. 615/2025 determina que os **dados utilizados no desenvolvimento ou treinamento de modelos de IA sejam anonimizados sempre que possível** – sendo *obrigatória a anonimização* no caso de dados sigilosos ou protegidos por segredo de justiça ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=%C2%A7%202%C2%BA%20Os%20dados%20dever%C3%A3o,pr%C3%A1ticas%20de%20tratamento%20de%20dados)). Além disso, devem ser coletados e usados **apenas os dados estritamente necessários** ao treinamento, evitando manter bases de dados sem propósito ou sem controle ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=de%20Dados%20Pessoais,sem%20uso%20ou%20controle%20quanto)). Essas medidas previnem riscos à privacidade e estão alinhadas aos princípios de **minimização de dados** da LGPD.

Outra preocupação é com a **confidencialidade dos conteúdos inseridos nos prompts**. Ao interagir com modelos de IA de grande porte oferecidos por terceiros (p. ex. chatbots públicos na nuvem), há o risco de que as informações submetidas sejam armazenadas nos servidores do provedor e potencialmente reutilizadas no treinamento futuro do modelo ou acessadas indevidamente. **Orientações judiciais internacionais advertem** a não inserir em ferramentas públicas de IA nenhum dado que não seja público ou que seja confidencial ([AI Judicial Guidance](https://www.judiciary.uk/wp-content/uploads/2023/12/AI-Judicial-Guidance.pdf#:~:text=Do%20not%20enter%20any%20information,to%20be%20used%20to%20respond)) ([AI Judicial Guidance](https://www.judiciary.uk/wp-content/uploads/2023/12/AI-Judicial-Guidance.pdf#:~:text=chatbot%20should%20be%20seen%20as,This%20option%20is%20currently)). Tudo que for digitado em um chatbot público deve ser tratado *“como se estivesse sendo publicado para o mundo”* ([AI Judicial Guidance](https://www.judiciary.uk/wp-content/uploads/2023/12/AI-Judicial-Guidance.pdf#:~:text=Do%20not%20enter%20any%20information,to%20be%20used%20to%20respond)), pois as consultas ficam registradas e poderiam ser acessadas por terceiros ou por brechas de segurança. Nesse sentido, tribunais devem **avaliar cuidadosamente as plataformas de IA antes do uso**, garantindo que atendam a requisitos de segurança e conformidade com regulamentos de privacidade ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=Courts%20should%20carefully%20evaluate%20AI,should%20be%20clear%20on%20the)). **Protocolos claros** devem ser desenvolvidos sobre **que informações podem ou não ser compartilhadas com ferramentas de IA generativa** ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=specialized%20vendors%20who%20can%20provide,GenAI%20tool%20is%20not%20used)). Por exemplo, o tribunal pode optar por soluções de IA **on-premises** (instaladas em ambiente próprio) ou em nuvens governamentais, de forma que dados sensíveis não saiam do controle institucional ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=using%20AI%20tools%2C%20courts%20must,use%2C%20ensuring%20they%20meet%20all)) ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=develop%20clear%20protocols%20for%20what,to%20train%20the%20tool%20itself)). Caso sejam utilizados serviços de fornecedores, contratos devem estabelecer com clareza a questão da propriedade, acesso e uso dos dados inseridos e gerados pela ferramenta ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=develop%20clear%20protocols%20for%20what,to%20train%20the%20tool%20itself)) – assegurando, por exemplo, que **informações sensíveis fornecidas ao modelo não serão empregadas para treinar modelos públicos**.  

Em termos práticos de engenharia de prompt, a proteção de dados requer: **(a)** excluir ou mascarar identificadores pessoais nos inputs; **(b)** configurar o sistema para **não retornar informações pessoais irrelevantes** (por exemplo, se a base de conhecimento da IA inclui dados pessoais, instruir o modelo a omitir detalhes não necessários à resposta); e **(c)** inserir lembretes de confidencialidade nos comandos, como *“não divulgar informações protegidas por sigilo”*. Vale ressaltar que a Res. 615/2025 impõe conformidade com a LGPD em todo o ciclo de vida da solução de IA, exigindo **mecanismos de monitoramento contínuo do tratamento de dados** e revisões periódicas das práticas de dados adotadas ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=acordo%20com%20as%20melhores%20pr%C3%A1ticas,discrimina%C3%A7%C3%A3o%20abusiva%20ou%20il%C3%ADcita%20e)) ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=%C2%A7%203%C2%BA%20Os%20tribunais%20dever%C3%A3o,auxiliem%20no%20julgamento%20justo%20e)). Em síntese, **todo prompt deve ser concebido com uma mentalidade de privacidade (privacy by design)**: somente pedir ao modelo o necessário, nunca expor dados sensíveis sem justificativa e sempre considerar o destino e registro das informações envolvidas.

## Redução de Vieses Algorítmicos e Promoção de Imparcialidade

Um desafio conhecido em sistemas de IA é a **possibilidade de reproduzirem ou até amplificarem vieses algorítmicos** presentes em seus dados de treinamento. No contexto jurídico, **imparcialidade** e **isonomia** são valores inegociáveis – qualquer tecnologia auxiliar deve **preservar a igualdade de tratamento das partes** e evitar discriminações (sejam explícitas ou veladas). A Resolução CNJ 615/2025 aborda esse tema de forma robusta, estabelecendo que os **dados usados no desenvolvimento e treinamento da IA devem ser representativos** dos casos judiciais, refletindo adequadamente a diversidade de situações e contextos do Judiciário, *“evitando vieses que possam comprometer a equidade e a justiça decisória”* ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=as%20cautelas%20necess%C3%A1rias%20quanto%20ao,por%20segredo%20de%20justi%C3%A7a%2C%20de)) ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=%C2%A7%201%C2%BA%20Consideram,dados%20e%20seguran%C3%A7a%20da%20informa%C3%A7%C3%A3o)). Em outras palavras, a base de conhecimento da IA deve cobrir diferentes gêneros, etnias, regiões, etc., para que o modelo não se torne tendencioso. Adicionalmente, a Resolução determina que **os produtos gerados pela IA para suporte às decisões preservem a igualdade, a não discriminação abusiva ou ilícita e a pluralidade**, ajudando a eliminar ou minimizar erros de julgamento decorrentes de preconceitos ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=Art,auxiliem%20no%20julgamento%20justo%20e)). 

No nível da **engenharia de prompts**, essas diretrizes se traduzem em várias boas práticas. Primeiro, **formular prompts de maneira neutra e imparcial**, sem enviesar a pergunta em favor de alguma parte ou pressuposto. Por exemplo, em vez de perguntar *“Por que o réu provavelmente é culpado neste caso?”* (o que induz a IA a procurar culpa), deve-se preferir um prompt equilibrado: *“Quais argumentos favorecem a culpa e quais favorecem a inocência do réu neste caso?”*. Assim, o modelo é instigado a considerar **múltiplas perspectivas** antes de concluir. Segundo, evitar incluir no prompt **estereótipos ou generalizações** que possam resultar em respostas preconceituosas. Terceiro, pode-se instruir explicitamente a IA, no próprio texto do prompt, a **não considerar atributos sensíveis** (raça, religião, gênero, etc.) a menos que sejam estritamente relevantes ao contexto jurídico da questão. Por exemplo: *“Elabore a decisão enfatizando apenas os fatos e fundamentos jurídicos, sem quaisquer referências a características pessoais das partes que não tenham pertinência com o caso.”* Essa orientação explícita ajuda a IA a filtrar informações potencialmente enviesadas na sua resposta.

As **medidas preventivas** contra vieses também envolvem **validação e monitoramento contínuos** das soluções de IA. A Res. 615/2025 preconiza a implementação de mecanismos para **detectar e mitigar vieses discriminatórios ao longo de todo o ciclo de vida** da aplicação de IA ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=%C2%A7%201%C2%BA%20Dever%C3%A3o%20ser%20implementadas,continuem%20em%20conformidade%20com%20os)). Isso inclui realizar testes com prompts diversos, verificando se o modelo responde de forma consistente e justa a diferentes formulações de uma mesma pergunta. Por exemplo, se fornecermos ao sistema cenários semelhantes variando apenas o grupo demográfico dos envolvidos, as respostas devem permanecer juridicamente equivalentes. Caso seja notada alguma disparidade (v.g., a IA sugerindo pena mais branda quando o réu pertence a certo grupo), isso indica um viés a ser corrigido. A resolução do CNJ impõe que **relatórios periódicos avaliem o impacto das soluções de IA no julgamento justo, imparcial e eficiente** ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=solu%C3%A7%C3%B5es%20de%20IA%20e%20a,continuem%20em%20conformidade%20com%20os)), o que sugere que órgãos judiciais devem coletar estatísticas e exemplos de saídas da IA para escrutínio. Internacionalmente, há recomendações no mesmo sentido: tribunais devem **monitorar ativamente as saídas da IA em busca de padrões ou linguagem enviesada**, garantindo que nenhum grupo seja prejudicado ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=While%20AI%20systems%20could%20be,disadvantage%20any%20groups%20or%20individuals)) ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=from%20other%20sources,effects%20on%20various%20stakeholder%20groups)). Protocolos de avaliação contínua e comitês de supervisão diversos são sugeridos para revisar implementações de IA e seus efeitos em diferentes segmentos do público ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=ensuring%20that%20the%20use%20of,trial%20release%2C%20sentencing%2C%20or)) ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=evaluation%20of%20AI%20systems%27%20impact,given%20that%20the%20algorithms%20used)).

Em prompts complexos, pode-se empregar técnicas para mitigar viés, como **pedir ao modelo para fornecer contrapontos**. Por exemplo: *“Apresente a recomendação de decisão e, em seguida, aponte possíveis contrargumentos a essa recomendação, considerando perspectivas diferentes.”* Isso força o modelo a não se fixar em apenas uma linha de raciocínio. Outra estratégia é usar **conjuntos de prompts de verificação**: após a IA gerar uma resposta para um prompt principal, submeter a ela novos prompts que testem a consistência daquela resposta. Se inconsistências ou preconceitos emergirem na etapa de verificação, o resultado inicial pode ser descartado ou ajustado. Em última instância, se determinados vieses não puderem ser eliminados, a Res. 615/2025 prevê que a solução de IA pode ter de ser suspensa ou descontinuada ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=princ%C3%ADpios%20da%20igualdade%2C%20pluralidade%20e,nesta%20Resolu%C3%A7%C3%A3o%2C%20dever%C3%A3o%20ser%20adotadas)), privilegiando-se sempre a **imparcialidade e a justiça humana** sobre a automação. Portanto, a engenharia de prompt em contexto jurídico deve ser iterativa e **orientada por princípios de equidade**, assumindo um compromisso de revisão e correção contínua para prevenir discriminações.

## Acurácia, Rastreabilidade e Auditabilidade das Respostas

No ambiente da Justiça, erros factuais ou jurídicos em respostas de IA podem ter consequências graves. Por isso, garantir a **acurácia** (correção) das informações geradas é crucial. Modelos de linguagem grandes, como os baseados em *deep learning*, tendem às vezes a produzir *alucinações* – ou seja, afirmações incorretas apresentadas como se fossem verdadeiras. Um caso notório envolveu um advogado que submeteu à corte um documento preparado com auxílio de IA contendo citações de jurisprudência inexistentes, fruto de invenção da ferramenta de linguagem ([AI Judicial Guidance](https://www.judiciary.uk/wp-content/uploads/2023/12/AI-Judicial-Guidance.pdf#:~:text=you%20should%20contact%20your%20leadership,disclosed%20information%20includes%20personal%20data)). Para evitar situações assim, a engenharia de prompt deve **orientar o modelo a se basear em fontes confiáveis e a indicar referências**. Uma técnica importante é incorporar no prompt pedidos explícitos de **citação de fontes ou trechos legais**. Por exemplo: *“Responda com base exclusiva no texto legal a seguir…”* ou *“Indique os artigos de lei ou precedentes que fundamentam sua conclusão”*. Quando a IA é restringida a um **contexto fornecido pelo usuário** – como um conjunto de leis, um acórdão ou um relatório anexo – ela tende a produzir respostas mais acuradas e verificáveis, pois está *“olhando”* apenas para informações validadas. Essa é a ideia por trás da técnica de **RAG (*Retrieval-Augmented Generation*)**, na qual o prompt inclui documentos ou dados auxiliares e instrui o modelo a **se ater somente àquelas fontes** ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Como%20funciona%3A%20a%20IA%20se,prim%C3%A1ria%2C%20sem%20incluir%20informa%C3%A7%C3%B5es%20externas)) ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=,trechos%20espec%C3%ADficos%20que%20as%20comprovam)). Por exemplo, ao anexar um relatório de auditoria e perguntar *“Indique as três principais vulnerabilidades jurídicas, citando trechos específicos do relatório que as comprovam”*, obtém-se uma resposta **rigorosamente embasada** no documento fornecido ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Exemplo%20pr%C3%A1tico%3A%20voc%C3%AA%20quer%20analisar,relat%C3%B3rio%20de%20auditoria%20sobre%20compliance)) – aumentando a precisão e evitando acréscimos indevidos.

Outra faceta essencial é a **rastreabilidade** e **auditabilidade** do processo de geração de respostas. *Rastreabilidade* refere-se à capacidade de identificar como e de onde a IA obteve determinado conteúdo ou conclusão. *Auditabilidade* significa que o sistema de IA pode ser submetido a avaliação de seus algoritmos, dados e resultados ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=XVII%20%E2%80%93%20auditabilidade%3A%20capacidade%20de,CAP%C3%8DTULO%20II)). Aplicada aos prompts, essa ideia se traduz na necessidade de **documentar o raciocínio ou os passos seguidos pelo modelo**. Uma técnica de engenharia de prompt muito útil aqui é a **“cadeia de pensamento” (*chain-of-thought*)**, que consiste em instruir a IA a **expor passo a passo seu raciocínio** antes de dar a resposta final ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Como%20funciona%3A%20o%20usu%C3%A1rio%20solicita,pensamento%20na%20produ%C3%A7%C3%A3o%20da%20resposta)). Com isso, o usuário humano consegue seguir a lógica adotada e identificar eventuais falhas ou suposições incorretas. Por exemplo, um prompt pode dizer: *“Explique seu processo de pensamento antes de concluir. Primeiro, enumere os fatos relevantes; depois analise cada requisito legal; por fim, apresente sua conclusão.”* ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=,a%20inexist%C3%AAncia%20do%20dano%20indeniz%C3%A1vel)). A IA então fornecerá uma resposta estruturada em etapas lógicas, o que **facilita a auditoria** por revelar como a conclusão foi construída. Vale ressaltar que a Res. 615/2025 inclui **“explicabilidade”** como princípio, definida como a possibilidade de se compreender claramente como as “decisões” são tomadas pela IA ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=sempre%20que%20tecnicamente%20poss%C3%ADvel%3B%20XVIII,CAP%C3%8DTULO%20II)). Embora modelos de linguagem não possuam transparência de caixa-branca em sua lógica interna, técnicas de prompt como essa ajudam a aproximar a saída do modelo de uma explicação inteligível.

Para reforçar a auditabilidade, o Judiciário também deve manter **registros detalhados de cada interação da IA que impacte processos judiciais**. Isso envolve logar os prompts submetidos, as respostas recebidas e, se aplicável, quais partes da resposta foram utilizadas em decisões ou atos. Tais registros permitem **verificação posterior por auditores independentes ou partes interessadas**, assegurando responsabilidade. A Res. 615/2025 exige que os tribunais implementem **mecanismos de auditoria e monitoramento contínuos** para garantir conformidade da IA com direitos fundamentais, ajustando o sistema sempre que incompatibilidades forem identificadas ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=%C2%A7%202%C2%BA%20Os%20tribunais%20dever%C3%A3o,a%20ajustes%20sempre%20que%20forem)). Também prevê que, havendo indícios de violação a direitos, entes como a Ordem dos Advogados do Brasil (OAB) e o Ministério Público possam ter acesso às avaliações de impacto algorítmico e pedir auditorias ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=%C2%A7%203%C2%BA%20Havendo%20not%C3%ADcia%20ou,que%20utilizem%20modelos%20de%20intelig%C3%AAncia)). Isso reflete a importância da **documentação e rastreabilidade**: somente com logs e relatórios completos será possível apurar, por exemplo, se um erro grave da IA decorreu de um prompt mal formulado, de um dado de treinamento inadequado ou de limitações intrínsecas do modelo.

Em termos de boas práticas de prompt para assegurar acurácia e rastreabilidade, podemos resumir: **(a)** **Fornecer dados de contexto de qualidade** (leis, casos, fatos relevantes) no próprio prompt sempre que viável, para ancorar a resposta em fontes verificáveis; **(b)** **Especificar no prompt o formato da resposta** requerendo seções explicativas, citações ou outros elementos que facilitem a conferência; **(c)** **Validar manualmente todas as informações cruciais** fornecidas pela IA antes de adotá-las (o humano continua “no laço” de decisão). Conforme diretrizes dos tribunais norte-americanos, *“a precisão de qualquer informação fornecida por uma ferramenta de IA deve ser verificada antes de ser utilizada”*, já que as informações podem estar incorretas, incompletas ou enviesadas ([AI Judicial Guidance](https://www.judiciary.uk/wp-content/uploads/2023/12/AI-Judicial-Guidance.pdf#:~:text=you%20should%20contact%20your%20leadership,disclosed%20information%20includes%20personal%20data)). De fato, orienta-se que **todas as citações e referências sugeridas pela IA sejam conferidas em fonte oficial** antes de citá-las num documento real. A IA pode ajudar a rascunhar, mas **cabe ao profissional jurídico garantir a acurácia** – e prompts bem estruturados tornam essa tarefa mais fácil ao produzir respostas claras, explicadas e com indicativos de origem.

## Técnicas Metodológicas para Prompts Confiáveis, Seguros e Eficientes

A engenharia de prompt evoluiu para um **conjunto de técnicas especializadas** que visam melhorar a confiabilidade, segurança e eficiência das respostas de IA. No contexto jurídico, a aplicação dessas técnicas pode auxiliar a obter resultados mais alinhados às necessidades profissionais e em conformidade com os critérios acima discutidos. A seguir, listam-se algumas das **principais técnicas de prompt engineering** e suas boas práticas, com exemplos adaptados ao cenário do Judiciário:

- **Prompt Específico e Contextualizado:** Escrever prompts **claros e específicos**, incluindo detalhes de contexto, formato desejado da resposta e outros parâmetros relevantes. Essa prática reduz ambiguidades e orienta a IA precisamente sobre o que se espera ([Prompt Engineering Best Practices: Tips, Tricks, and Tools | DigitalOcean](https://www.digitalocean.com/resources/articles/prompt-engineering-best-practices#:~:text=1,possible)) ([Prompt Engineering Best Practices: Tips, Tricks, and Tools | DigitalOcean](https://www.digitalocean.com/resources/articles/prompt-engineering-best-practices#:~:text=When%20creating%20the%20best%20prompts,ask%20for%20the%20following%20specifics)). *Exemplo:* em vez de pedir *“Resuma o processo”*, um prompt específico seria: *“Resuma os fatos e o resultado da Ação X (uma ação de indenização por acidente de trabalho), em no máximo 5 parágrafos, com tom formal e impessoal, destacando a decisão final.”*. Aqui, definimos o escopo (fatos e resultado), o contexto (tipo de ação), a extensão (até 5 parágrafos) e o estilo (formal). Quanto mais bem delimitado o prompt, **melhor a aderência da resposta ao que se necessita**.

- **Fornecimento de Exemplos (Few-shot Prompting):** Incluir **exemplos de entrada e saída** para guiar o modelo é extremamente útil quando se deseja um estilo ou formato específico ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Como%20funciona%3A%20voc%C3%AA%20fornece%20%C3%A0,de%20documento%2C%20argumenta%C3%A7%C3%A3o%20ou%20comunica%C3%A7%C3%A3o)) ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Exemplo%20pr%C3%A1tico%3A%20seu%20escrit%C3%B3rio%20j%C3%A1,acompanhamento%20processual%20para%20um%20cliente)). Ao mostrar à IA dois ou três exemplos de como uma tarefa deve ser feita, ela tende a replicar o padrão. *Exemplo:* para treinar a IA a redigir notificação padrão a clientes sobre andamento processual, pode-se fornecer modelos de notificações anteriores (anonimizadas) seguidos do comando: *“Agora, com base nesses exemplos, escreva uma notificação ao cliente Fulano sobre o processo Y, mantendo o mesmo tom e formato dos modelos acima.”* ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Exemplo%20pr%C3%A1tico%3A%20seu%20escrit%C3%B3rio%20j%C3%A1,acompanhamento%20processual%20para%20um%20cliente)). Com isso, a IA **aprende pelo exemplo** e gera um texto consistente com as práticas do escritório.

- **Cadeia de Pensamento (*Chain-of-Thought*):** Conforme mencionado, trata-se de instruir a IA a **pensar passo a passo**. Essa técnica aumenta a coerência lógica e a qualidade da argumentação ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Como%20funciona%3A%20o%20usu%C3%A1rio%20solicita,pensamento%20na%20produ%C3%A7%C3%A3o%20da%20resposta)). *Exemplo:* na elaboração de uma decisão judicial complexa, o prompt pode dizer: *“Há responsabilidade civil do empregador neste caso? Vamos pensar passo a passo: primeiro, enumere os fatos relevantes; em seguida, analise a existência de culpa ou dolo do empregador; depois, verifique o nexo de causalidade; por fim, conclua se há dano indenizável.”* ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=,a%20inexist%C3%AAncia%20do%20dano%20indeniz%C3%A1vel)). A resposta virá estruturada em partes, permitindo verificar cada etapa do raciocínio jurídico. Essa metodologia não só melhora a **clareza da peça jurídica** gerada ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=sua%20aus%C3%AAncia,a%20inexist%C3%AAncia%20do%20dano%20indeniz%C3%A1vel)), como também previne omissões de pontos importantes, tornando o resultado mais robusto.

- **Encadeamento de Prompts (*Prompt Chaining*):** Consiste em **dividir a tarefa em etapas** e usar a saída de um prompt como entrada para o próximo, refinando gradualmente o resultado ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Prompt%20Chaining)) ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=%2A%20Prompt%202%3A%20,brasileira%20e%20pronta%20para%20assinatura)). Essa técnica é valiosa para tarefas longas ou complexas, pois a IA pode focar em cada parte separadamente. *Exemplo:* para redigir um contrato, pode-se começar com *“Gere um esboço básico do contrato, incluindo apenas cláusulas centrais (objeto e remuneração)”* (Prompt 1); depois *“Agora refine o texto, incorporando artigos relevantes da legislação (Lei X/XX) e detalhando direitos e deveres”* (Prompt 2); por fim *“Revise e entregue a versão final, bem estruturada, cumprindo os requisitos formais legais e pronta para assinatura”* (Prompt 3) ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Exemplo%20pr%C3%A1tico%3A%20constru%C3%A7%C3%A3o%20de%20contrato,de%20representa%C3%A7%C3%A3o%20comercial)). Cada etapa incrementa o nível de detalhe e correção do documento, sob supervisão do usuário. Essa abordagem garante **maior controle de qualidade**, pois em cada passo pode-se revisar e ajustar o curso antes de prosseguir.

- **Geração de Resposta com Recuperação de Dados (RAG – *Retrieval-Augmented Generation*):** Aqui, integra-se ao prompt **informações auxiliares** (documentos, legislação, precedentes) para que a IA gere a resposta *exclusivamente* embasada nesses dados fornecidos ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Como%20funciona%3A%20a%20IA%20se,prim%C3%A1ria%2C%20sem%20incluir%20informa%C3%A7%C3%B5es%20externas)) ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=,trechos%20espec%C3%ADficos%20que%20as%20comprovam)). É uma forma de “alimentar” temporariamente o modelo com um contexto confiável. *Exemplo:* anexar a íntegra de um relatório de auditoria e perguntar: *“Com base **exclusiva** no relatório anexado, liste as principais não conformidades encontradas, citando os trechos do texto que evidenciam cada uma.”* ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Exemplo%20pr%C3%A1tico%3A%20voc%C3%AA%20quer%20analisar,relat%C3%B3rio%20de%20auditoria%20sobre%20compliance)). Assim, a IA atuará quase como um mecanismo de busca e síntese dentro do conteúdo entregue, **evitando buscar informações externas possivelmente incorretas**. Essa técnica é particularmente útil para assegurar a **segurança jurídica** das respostas, pois garante que o modelo não “imagine” fatos não contidos no material autorizado.

- **ReAct (Raciocínio e Ação):** Método em que o modelo alterna entre **etapas de reflexão interna e consultas a uma fonte de dados** fornecida, de modo interativo ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=ReAct%20)) ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=,mencione%20explicitamente%20os%20documentos%20utilizados)). O ReAct combina a cadeia de pensamento com a recuperação de dados sob demanda: a IA “pensa” alguns passos, identifica a necessidade de uma informação específica, então “age” buscando nos documentos anexos, retornando ao raciocínio em seguida ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Como%20funciona%3A%20a%20IA%20alterna,proporcionando%20uma%20abordagem%20mais%20din%C3%A2mica)) ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=anexo.%20%2A%20Prompt%3A%20,mencione%20explicitamente%20os%20documentos%20utilizados)). *Exemplo:* em alegações finais de um processo trabalhista, fornecem-se os depoimentos e provas anexos, e o prompt instrui: *“Com base nas provas anexadas, elabore as alegações finais detalhando os pontos favoráveis ao réu, mencionando explicitamente os documentos utilizados como suporte.”* ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Exemplo%20pr%C3%A1tico%3A%20elabora%C3%A7%C3%A3o%20de%20alega%C3%A7%C3%B5es,finais%20num%20processo%20trabalhista)). A IA organizará o texto e, sempre que precisar de um dado (uma data, um trecho de e-mail, etc.), consultará internamente os anexos (porque assim foi orientada) antes de continuar ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=anexo.%20%2A%20Prompt%3A%20,mencione%20explicitamente%20os%20documentos%20utilizados)). O resultado é uma resposta mais dinâmica e precisa, **fundamentada diretamente nas evidências do caso**, o que eleva sua confiabilidade.

- **Autorrevisão (*Reflexion*):** Técnica emergente em que a IA, após gerar uma resposta inicial, **revê criticamente seu próprio output** e o aprimora antes de apresentar ao usuário ([Guia de prompt engineering para advogados: 7 técnicas para transformar seu uso de IA (a última você ainda não conhece!)](https://pt.linkedin.com/pulse/guia-de-prompt-engineering-para-advogados-7-t%C3%A9cnicas-transformar-k4tsf#:~:text=Reflexion)). Essa autorreflexão permite identificar inconsistências ou melhorias de forma e conteúdo. *Exemplo:* a IA elabora um parecer jurídico, então é instruída: *“Releia o parecer acima e critique-o: houve algum ponto obscuro ou argumento faltante? Revise o texto para corrigir eventuais falhas ou acrescentar esclarecimentos necessários.”*. A IA então produz uma versão revisada, mais concisa e precisa. Esse processo pode incrementar a **qualidade final** do texto e reduzir erros, servindo como uma camada adicional de segurança antes da validação humana definitiva.

- **Proteção contra *Prompt Injection* e Instruções Maliciosas:** Em termos de segurança, os prompts também devem ser concebidos para **resistir a ataques de “injeção de prompt”**, que ocorrem quando entradas maliciosas tentam burlar as instruções originais do sistema ([Prompt injections e accountability em sistemas de IA - Migalhas](https://www.migalhas.com.br/coluna/migalhas-de-protecao-de-dados/428264/prompt-injections-e-accountability-em-sistemas-de-ia#:~:text=O%20prompt%20injection%20consiste%20na,intensificou%20a%20gravidade%20desses%20ataques)). Por exemplo, um usuário mal-intencionado poderia inserir um comando escondido no meio de um texto aparentemente legítimo para induzir a IA a violar regras (como revelar dados sigilosos ou executar ação não permitida) ([Prompt injections e accountability em sistemas de IA - Migalhas](https://www.migalhas.com.br/coluna/migalhas-de-protecao-de-dados/428264/prompt-injections-e-accountability-em-sistemas-de-ia#:~:text=A%20maleabilidade%20sem%C3%A2ntica%20dos%20modelos,na%20facilita%C3%A7%C3%A3o%20de%20condutas%20il%C3%ADcitas)) ([Prompt injections e accountability em sistemas de IA - Migalhas](https://www.migalhas.com.br/coluna/migalhas-de-protecao-de-dados/428264/prompt-injections-e-accountability-em-sistemas-de-ia#:~:text=viola%C3%A7%C3%B5es%20de%20privacidade%2C%20divulga%C3%A7%C3%A3o%20de,na%20facilita%C3%A7%C3%A3o%20de%20condutas%20il%C3%ADcitas)). Para mitigar esse risco, recomenda-se **utilizar sistemas de filtragem e validação das entradas** antes de submetê-las ao modelo ([Prompt injections e accountability em sistemas de IA - Migalhas](https://www.migalhas.com.br/coluna/migalhas-de-protecao-de-dados/428264/prompt-injections-e-accountability-em-sistemas-de-ia#:~:text=Um%20fator%20essencial%20para%20compreender,intencionada)) ([Prompt injections e accountability em sistemas de IA - Migalhas](https://www.migalhas.com.br/coluna/migalhas-de-protecao-de-dados/428264/prompt-injections-e-accountability-em-sistemas-de-ia#:~:text=Contudo%2C%20tais%20provid%C3%AAncias%20n%C3%A3o%20garantem,em%20seu%20n%C3%BAcleo%20de%20controle)). Na prática, isso pode significar ter uma etapa de pré-processamento que sanitiza o input do usuário (remoção de trechos potencialmente perigosos ou linguagem ambígua) e a adoção de **prompts “sistemas”** com instruções firmes para o modelo ignorar comandos do usuário que conflitem com políticas de segurança. Adicionalmente, **múltiplas camadas de proteção** são sugeridas: autenticação de usuários (para saber quem envia prompts), criptografia de instruções (dificultando interferências externas) e monitoramento de anomalias nas conversações ([Prompt injections e accountability em sistemas de IA - Migalhas](https://www.migalhas.com.br/coluna/migalhas-de-protecao-de-dados/428264/prompt-injections-e-accountability-em-sistemas-de-ia#:~:text=Um%20fator%20essencial%20para%20compreender,intencionada)). Em última instância, é importante que o prompt deixe claro para a IA quais limites não devem ser ultrapassados – por exemplo: *“Se o usuário pedir algo contrário à lei ou às políticas X, recuse educadamente”*. Essa abordagem implementa **“guardrails” (trilhos de segurança) embutidos no próprio prompt**, conforme recomendado por especialistas ([The Art and Science of Prompt Engineering: Unlocking AI’s True Potential in 2025 | by SHREEDEVI T S | Apr, 2025 | Medium](https://medium.com/@Shreedevi-TS/the-art-and-science-of-prompt-engineering-unlocking-ais-true-potential-in-2025-346154144ac1#:~:text=%E2%80%9CResponsible%20prompt%20engineering%20includes%20designing,%E2%80%9D)). Combinadas, essas medidas aumentam a **resiliência** do sistema de IA contra manipulações indevidas, assegurando que ele se mantenha dentro dos conformes esperados.

Em suma, existe hoje um *arsenal de técnicas de engenharia de prompt* que, quando bem aplicadas, elevam significativamente a **confiabilidade, segurança e eficiência** das aplicações de IA. A chave é escolher a técnica adequada a cada caso de uso e **testar iterativamente** os prompts, refinando-os de acordo com os resultados obtidos. Para a esfera jurídica, onde precisão e prudência são vitais, essas técnicas permitem aproveitar o poder das IAs generativas sem abrir mão do rigor e da segurança exigidos.

## Frameworks e Recomendações Institucionais em Engenharia de Prompt

Diversas instituições públicas e organismos reguladores, no Brasil e no exterior, têm desenvolvido **frameworks e recomendações** para orientar o uso responsável da IA – o que inclui boas práticas relacionadas à engenharia de prompt. No caso brasileiro, a própria **Resolução CNJ n.º 615/2025** pode ser vista como um marco normativo abrangente que estabelece princípios e procedimentos para a incorporação da IA no Judiciário. Ela demanda que cada tribunal **institua diretrizes internas** alinhadas aos seus princípios ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=Par%C3%A1grafo%20%C3%BAnico,e%20%C3%A0%20prote%C3%A7%C3%A3o%20de%20dados)) e define requisitos como supervisão humana, transparência, equidade, segurança da informação, entre outros, que **influenciam diretamente a forma de projetar prompts** (visto que os prompts são o meio de interação com as soluções de IA). Além disso, a Resolução criou instâncias de governança – como o Comitê Nacional de Inteligência Artificial do Judiciário – e prevê avaliações de impacto algorítmico e **categorização de riscos** das aplicações de IA ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=princ%C3%ADpios%20da%20igualdade%2C%20pluralidade%20e,nesta%20Resolu%C3%A7%C3%A3o%2C%20dever%C3%A3o%20ser%20adotadas)) ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=modelos%20de%20intelig%C3%AAncia%20artificial%20devem,equidade%20e%20a%20justi%C3%A7a%20decis%C3%B3ria)), o que se conecta à necessidade de ajustar os usos da IA (e os prompts correspondentes) conforme o nível de risco envolvido na tarefa. Em síntese, o CNJ oferece um *framework normativo* que integra considerações éticas, técnicas e legais, servindo de referência para outros órgãos públicos que venham a adotar IA.

No panorama internacional, há esforços similares. Nos Estados Unidos, por exemplo, a **Conferência Nacional das Cortes Estaduais (NCSC)** publicou em 2025 orientações e princípios para uso de IA nos tribunais, enfatizando pontos como **supervisão humana, verificação de acurácia, confidencialidade, transparência e prevenção de vieses** ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=1,center%20of%20our%20court%20system)) ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=While%20AI%20systems%20could%20be,disadvantage%20any%20groups%20or%20individuals)) – todos eles fatores a serem endereçados tanto na configuração dos sistemas quanto na elaboração dos prompts. O documento recomenda estabelecer **protocolos claros** sobre uso de dados (para que informações confidenciais não sejam expostas ou utilizadas para treinar indevidamente os modelos) ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=develop%20clear%20protocols%20for%20what,to%20train%20the%20tool%20itself)), **comunicar abertamente** o uso de IA às partes interessadas (dando transparência) ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=Courts%20must%20maintain%20open%20and,facing%20GenAI)), e **monitorar continuamente** saídas para evitar discriminações ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=While%20AI%20systems%20could%20be,disadvantage%20any%20groups%20or%20individuals)). Também salienta a importância de **capacitação dos usuários internos** (juízes e servidores) para que compreendam o funcionamento e limitações das IAs ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=While%20AI%20systems%20could%20be,disadvantage%20any%20groups%20or%20individuals)) ([Principles and Practices for AI in State Courtsfinal85[5]](https://www.ncsc.org/__data/assets/pdf_file/0017/110168/Principles-and-Practices-for-AI-in-State-Courts.pdf#:~:text=evaluation%20of%20AI%20systems%27%20impact,given%20that%20the%20algorithms%20used)). Essa capacitação envolve treinamento em elaborar bons prompts, interpretar respostas da IA criticamente e preservar padrões éticos no uso da tecnologia – elemento igualmente presente na Res. 615/2025, que prevê oferta de capacitação contínua em IA para magistrados e servidores, com foco em riscos da automação e vieses algorítmicos ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=Art,e%20representatividade%2C%20com%20%C3%AAnfase%20na)).

No Reino Unido, **diretrizes judiciais sobre IA** (dezembro de 2023) abordam explicitamente a interação com ferramentas como chatbots generativos, recomendando que juízes **não utilizem informações privadas em serviços públicos de IA** e ressaltando que, no estado atual, modelos como ChatGPT podem fornecer respostas incompletas ou enviesadas que **devem ser rigorosamente verificadas** antes de qualquer uso oficial ([AI Judicial Guidance](https://www.judiciary.uk/wp-content/uploads/2023/12/AI-Judicial-Guidance.pdf#:~:text=Do%20not%20enter%20any%20information,to%20be%20used%20to%20respond)) ([AI Judicial Guidance](https://www.judiciary.uk/wp-content/uploads/2023/12/AI-Judicial-Guidance.pdf#:~:text=you%20should%20contact%20your%20leadership,disclosed%20information%20includes%20personal%20data)). Essas diretrizes convergem para a noção de que **políticas institucionais claras** devem reger o uso de IA: por exemplo, orientando que se utilize apenas dispositivos de trabalho para acessar IA, que se desabilite o histórico de conversas (para reduzir armazenamento indevido) e que se faça revisão humana de todo output antes de incorporá-lo a decisões ([AI Judicial Guidance](https://www.judiciary.uk/wp-content/uploads/2023/12/AI-Judicial-Guidance.pdf#:~:text=Do%20not%20enter%20any%20information,to%20be%20used%20to%20respond)) ([AI Judicial Guidance](https://www.judiciary.uk/wp-content/uploads/2023/12/AI-Judicial-Guidance.pdf#:~:text=you%20should%20contact%20your%20leadership,disclosed%20information%20includes%20personal%20data)).

Organismos multilaterais também oferecem **frameworks de IA confiável** que influenciam as práticas de prompt. A União Europeia, embora ainda em fase regulatória (com o projeto do AI Act), já elencou requisitos para *IA confiável* como transparência, accountability, robustez e respeito aos direitos – o que implica, por exemplo, que sistemas de IA em setores de alto risco (como justiça) devem ser **explicáveis e auditáveis**, devendo suas interações (prompts incluídos) ser registradas para escrutínio. A **OCDE** e a **UNESCO** propuseram princípios éticos para IA que abrangem *não discriminação, segurança, transparência e supervisão humana*, servindo de referência para governos ao redor do mundo. Tais princípios de alto nível refletem-se nas recomendações de prompt engineering: a UNESCO, por exemplo, destaca a importância de **avaliar e mitigar preconceitos em algoritmos**, o que reforça a necessidade de testes com prompts variados para detectar vieses. 

Além de diretrizes gerais, começam a surgir **frameworks específicos para engenharia de prompt**. Empresas de tecnologia e comunidades de pesquisa têm publicado guias de boas práticas – alguns dos quais já mencionados, abordando **mitigação de vieses, proteção de dados e inserção de constraints éticas nos prompts** ([The Art and Science of Prompt Engineering: Unlocking AI’s True Potential in 2025 | by SHREEDEVI T S | Apr, 2025 | Medium](https://medium.com/@Shreedevi-TS/the-art-and-science-of-prompt-engineering-unlocking-ais-true-potential-in-2025-346154144ac1#:~:text=Leading%20organizations%20have%20developed%20prompt,that%20incorporate%20ethical%20considerations%20like)). Grandes organizações que adotam IA em escala estão estabelecendo **equipes dedicadas de prompt engineering** e codificando padrões internos para criação de prompts seguros ([The Art and Science of Prompt Engineering: Unlocking AI’s True Potential in 2025 | by SHREEDEVI T S | Apr, 2025 | Medium](https://medium.com/@Shreedevi-TS/the-art-and-science-of-prompt-engineering-unlocking-ais-true-potential-in-2025-346154144ac1#:~:text=%E2%80%9CResponsible%20prompt%20engineering%20includes%20designing,%E2%80%9D)) ([The Art and Science of Prompt Engineering: Unlocking AI’s True Potential in 2025 | by SHREEDEVI T S | Apr, 2025 | Medium](https://medium.com/@Shreedevi-TS/the-art-and-science-of-prompt-engineering-unlocking-ais-true-potential-in-2025-346154144ac1#:~:text=Leading%20organizations%20have%20developed%20prompt,that%20incorporate%20ethical%20considerations%20like)). Por exemplo, conforme relatado por Mora (2025), **organizações líderes desenvolvem manuais que incorporam considerações de equidade, transparência, privacidade, atribuição adequada e inclusão cultural na elaboração de prompts** ([The Art and Science of Prompt Engineering: Unlocking AI’s True Potential in 2025 | by SHREEDEVI T S | Apr, 2025 | Medium](https://medium.com/@Shreedevi-TS/the-art-and-science-of-prompt-engineering-unlocking-ais-true-potential-in-2025-346154144ac1#:~:text=Leading%20organizations%20have%20developed%20prompt,that%20incorporate%20ethical%20considerations%20like)). Esses manuais muitas vezes incluem checklists para autores de prompt: verificar se não há linguagem potencialmente tendenciosa, se o prompt deixa claro o contexto e objetivo legítimo, se protege segredos comerciais ou pessoais, etc. No setor público, iniciativas como a criação de uma **“credencial em Prompt Engineering” para servidores federais** nos EUA ([The federal government wants to teach workers about AI prompt ...](https://fedscoop.com/the-federal-government-wants-to-teach-workers-about-ai-prompt-engineering/#:~:text=The%20federal%20government%20wants%20to,and%20focuses%20on%20practical%20techniques)) ilustram o reconhecimento de que **saber interagir com IA de forma responsável é uma competência chave** a ser desenvolvida institucionalmente.

Por fim, vale citar a importância de **abordagens multidisciplinares e colaborativas** na definição de frameworks de IA no Judiciário. A Res. 615/2025 determina que as equipes de desenvolvimento de soluções de IA tenham diversidade e representatividade, envolvendo profissionais de diversas áreas ([](https://atos.cnj.jus.br/files/original1555302025031467d4517244566.pdf#:~:text=Art,e%20representatividade%2C%20com%20%C3%AAnfase%20na)). Isso sugere que a criação de prompts e casos de uso deve ser discutida entre tecnólogos, juristas, especialistas em ética e em proteção de dados, para que as soluções finais reflitam um equilíbrio de visões. Essa governança inclusiva, associada a **auditorias independentes periódicas** ([Prompt injections e accountability em sistemas de IA - Migalhas](https://www.migalhas.com.br/coluna/migalhas-de-protecao-de-dados/428264/prompt-injections-e-accountability-em-sistemas-de-ia#:~:text=Pol%C3%ADticas%20corporativas%20robustas%20de%20seguran%C3%A7a,e%20antecipar%20a%20vulnerabilidades%20ocultas)) ([Prompt injections e accountability em sistemas de IA - Migalhas](https://www.migalhas.com.br/coluna/migalhas-de-protecao-de-dados/428264/prompt-injections-e-accountability-em-sistemas-de-ia#:~:text=do%20modelo,4)), consolida um ecossistema no qual as práticas de engenharia de prompt estão em constante melhoria e alinhamento com os valores democráticos.

## Conclusão

A incorporação da inteligência artificial nas atividades do Poder Judiciário brasileiro traz enormes potenciais de eficiência e inovação, mas também impõe responsabilidades significativas. A **engenharia de prompt** desponta, nesse cenário, como uma ferramenta metodológica crucial para **orientar o comportamento dos modelos de IA** de acordo com os princípios e regras que regem a Justiça. Por meio de prompts cuidadosamente planejados, é possível **materializar diretrizes éticas**, resguardar a privacidade e a segurança dos dados, **minimizar vieses** e assegurar que as respostas geradas sejam **acuradas, auditáveis e úteis** ao processo judicial.

Este relatório examinou as diretrizes conceituais e metodológicas de boas práticas em engenharia de prompt, articulando as normas estabelecidas pelo CNJ – em especial a Resolução 615/2025 – com insights de pesquisas e recomendações especializadas. Evidenciou-se que muitos dos valores tradicionais do Direito (imparcialidade, transparência, contraditório, etc.) podem e devem ser traduzidos em cuidados práticos na formulação de prompts e na configuração de sistemas de IA. **Princípios éticos** precisam guiar cada interação homem-máquina, e **mecanismos de transparência** devem ser incorporados para que a participação da IA nos processos seja sempre clara e passível de escrutínio. **Proteção de dados** não é opcional: é imperativo legal e técnico, alcançado por meio de anonimização, restrição de informações sensíveis e escolha responsável das plataformas de IA. **Biases algorítmicos** são um risco real, mas que pode ser mitigado combinando diversidade de dados, orientação equilibrada dos prompts e monitoramento contínuo das saídas. Já a **acurácia e a auditabilidade** são fomentadas por estratégias de prompt que exigem justificativas e referências, bem como por uma supervisão humana diligente e registro completo das operações.

No campo metodológico, diversas técnicas – de *chain-of-thought* a *prompt chaining*, de RAG ao ReAct – compõem o repertório do profissional que elabora prompts avançados, permitindo modelar as respostas de IA de forma mais controlada, segura e eficiente. Essas técnicas não são fórmulas mágicas, mas sim **ferramentas a serem combinadas com conhecimento jurídico e bom senso**. Em última análise, a engenharia de prompt bem-sucedida no Judiciário será aquela que **potencializa a capacidade de trabalho e análise**, sem jamais subverter a autonomia decisória, a qualidade técnica ou a justiça das decisões humanas. Conforme bem resumiu Ahmed Khalid, *“os melhores engenheiros de prompt são tradutores entre a ambição humana e a capacidade da IA”* ([The Art and Science of Prompt Engineering: Unlocking AI’s True Potential in 2025 | by SHREEDEVI T S | Apr, 2025 | Medium](https://medium.com/@Shreedevi-TS/the-art-and-science-of-prompt-engineering-unlocking-ais-true-potential-in-2025-346154144ac1#:~:text=Conclusion%3A%20The%20Human%20Element%20Remains,Essential)) – no contexto jurídico, essa tradução deve ser fiel aos valores do Estado de Direito.

Em conclusão, o desenvolvimento de uma **cultura de boas práticas** em engenharia de prompt, apoiada por diretrizes claras, treinamento contínuo e frameworks de governança, é essencial para que a IA seja uma aliada do Judiciário. Seguindo os princípios e métodos aqui delineados, é possível colher os frutos da tecnologia – celeridade, acesso à informação, padronização – **sem descuidar das garantias legais e dos direitos fundamentais** que constituem a base da confiança na Justiça. O desafio é contínuo e evolutivo: à medida que os modelos de IA avançam, as diretrizes de prompt engineering também deverão ser refinadas. Contudo, com os alicerces éticos e metodológicos adequados, o Poder Judiciário estará apto a navegar na era da inteligência artificial de forma **transparente, responsável e eficaz**, sempre **a serviço da justiça**. ([](https://www.tjsp.jus.br/Download/SecaoDireitoPublico/Pdf/Cadip/INF-ESPECIAL-CADIP-IA-2ed-2025-03-26.pdf#:~:text=de%20forma%20justa%20e%20imparcial%2C,rigorosas%20para%20a%20prote%C3%A7%C3%A3o%20de)) ([](https://www.tjsp.jus.br/Download/SecaoDireitoPublico/Pdf/Cadip/INF-ESPECIAL-CADIP-IA-2ed-2025-03-26.pdf#:~:text=novo%20ato%20normativo%20estabeleceu%20requisitos,rigorosas%20para%20a%20prote%C3%A7%C3%A3o%20de))